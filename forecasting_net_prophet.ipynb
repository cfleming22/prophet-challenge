{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting Net Prophet\n",
    "\n",
    "## Data Validation Framework\n",
    "This notebook includes integrated validation steps to ensure data quality and accurate analysis.\n",
    "\n",
    "### Validation Checkpoints:\n",
    "1. Data Loading & Structure\n",
    "2. Time Series Continuity\n",
    "3. Calculation Verification\n",
    "4. Visualization Quality\n",
    "\n",
    "Each section includes validation cells marked with [VALIDATE] to ensure accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install the required libraries\n",
    "!pip install prophet\n",
    "!pip install hvplot\n",
    "!pip install holoviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import the required libraries and dependencies\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Validation\n",
    "\n",
    "Before proceeding with analysis, we'll validate our data sources and structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# [VALIDATE] Data Loading and Structure\n",
    "def validate_dataframe(df, expected_cols):\n",
    "    \"\"\"Validate DataFrame structure and content\"\"\"\n",
    "    validation_results = {\n",
    "        'rows': len(df),\n",
    "        'columns': list(df.columns),\n",
    "        'missing_values': df.isnull().sum().to_dict(),\n",
    "        'dtypes': df.dtypes.to_dict(),\n",
    "        'index_type': str(df.index.dtype)\n",
    "    }\n",
    "    print(\"Validation Results:\")\n",
    "    for key, value in validation_results.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    # Verify expected columns\n",
    "    missing_cols = set(expected_cols) - set(df.columns)\n",
    "    if missing_cols:\n",
    "        print(f\"WARNING: Missing expected columns: {missing_cols}\")\n",
    "    \n",
    "    return validation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Find Unusual Patterns in Hourly Google Search Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load and validate search trends data\n",
    "df_mercado_trends = pd.read_csv(\n",
    "    \"Resources/google_hourly_search_trends.csv\",\n",
    "    index_col='Date',\n",
    "    parse_dates=True\n",
    ").dropna()\n",
    "\n",
    "# [VALIDATE] Search trends data\n",
    "validate_dataframe(df_mercado_trends, ['Search Trends'])\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df_mercado_trends.head())\n",
    "print(\"\\nLast 5 rows:\")\n",
    "display(df_mercado_trends.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# [VALIDATE] Time series continuity\n",
    "def validate_time_series(df):\n",
    "    \"\"\"Validate time series data for gaps and consistency\"\"\"\n",
    "    print(f\"Date Range: {df.index.min()} to {df.index.max()}\")\n",
    "    print(f\"Total Hours: {len(df)}\")\n",
    "    \n",
    "    # Check for gaps\n",
    "    expected_hours = pd.date_range(start=df.index.min(), end=df.index.max(), freq='H')\n",
    "    missing_dates = set(expected_hours) - set(df.index)\n",
    "    if missing_dates:\n",
    "        print(f\"WARNING: Found {len(missing_dates)} missing hourly data points\")\n",
    "        print(\"Sample missing dates:\", list(missing_dates)[:5])\n",
    "\n",
    "validate_time_series(df_mercado_trends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze May 2020 patterns\n",
    "may_2020 = df_mercado_trends['2020-05']\n",
    "\n",
    "# Calculate total search traffic for May 2020\n",
    "traffic_may_2020 = may_2020['Search Trends'].sum()\n",
    "print(f\"Total Search Traffic for May 2020: {traffic_may_2020}\")\n",
    "\n",
    "# Calculate monthly median across all months\n",
    "monthly_traffic = df_mercado_trends.groupby([df_mercado_trends.index.year, \n",
    "                                            df_mercado_trends.index.month])['Search Trends'].sum()\n",
    "median_monthly_traffic = monthly_traffic.median()\n",
    "print(f\"\\nMedian Monthly Traffic: {median_monthly_traffic}\")\n",
    "\n",
    "# Compare May 2020 to median\n",
    "may_2020_ratio = traffic_may_2020 / median_monthly_traffic\n",
    "print(f\"\\nMay 2020 vs Median Ratio: {may_2020_ratio:.2f}\")\n",
    "\n",
    "# Visualize May 2020 trends\n",
    "plt.figure(figsize=(15, 7))\n",
    "may_2020['Search Trends'].plot()\n",
    "plt.title('Google Search Trends - May 2020')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Search Trends')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Did the Google search traffic increase during the month that MercadoLibre released its financial results?\n",
    "\n",
    "**Answer:** Based on the analysis above, [to be completed after running the analysis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Mine the Search Traffic Data for Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze hourly patterns\n",
    "hourly_trends = df_mercado_trends.groupby(df_mercado_trends.index.hour)['Search Trends'].mean()\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "hourly_trends.plot(kind='bar')\n",
    "plt.title('Average Search Traffic by Hour of Day')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Average Search Trends')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze day-of-week patterns\n",
    "daily_trends = df_mercado_trends.groupby(df_mercado_trends.index.dayofweek)['Search Trends'].mean()\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "daily_trends.plot(kind='bar')\n",
    "plt.title('Average Search Traffic by Day of Week')\n",
    "plt.xlabel('Day of Week (0=Monday, 6=Sunday)')\n",
    "plt.ylabel('Average Search Trends')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze weekly patterns\n",
    "weekly_trends = df_mercado_trends.groupby(df_mercado_trends.index.isocalendar().week)['Search Trends'].mean()\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "weekly_trends.plot()\n",
    "plt.title('Average Search Traffic by Week of Year')\n",
    "plt.xlabel('Week of Year')\n",
    "plt.ylabel('Average Search Trends')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Are there any time-based trends that you can see in the data?\n",
    "\n",
    "**Answer:** [to be completed after running the analysis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Relate the Search Traffic to Stock Price Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load and plot stock price data\n",
    "df_mercado_stock = pd.read_csv(\n",
    "    \"Resources/mercado_stock_price.csv\",\n",
    "    index_col=\"date\",\n",
    "    parse_dates=True\n",
    ").dropna()\n",
    "\n",
    "# Plot stock prices\n",
    "plt.figure(figsize=(15, 7))\n",
    "df_mercado_stock['close'].plot()\n",
    "plt.title('MercadoLibre Stock Price')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Price')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Concatenate the stock and search data\n",
    "mercado_stock_trends_df = pd.concat([df_mercado_stock, df_mercado_trends], axis=1)\n",
    "\n",
    "# Slice to the first half of 2020\n",
    "first_half_2020 = mercado_stock_trends_df.loc['2020-01':'2020-06']\n",
    "\n",
    "# Plot the stock and search trends data\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "first_half_2020['close'].plot(ax=ax1)\n",
    "ax1.set_title('Stock Price - First Half 2020')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Close Price')\n",
    "ax1.grid(True)\n",
    "\n",
    "first_half_2020['Search Trends'].plot(ax=ax2)\n",
    "ax2.set_title('Search Trends - First Half 2020')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Search Trends')\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create new columns for analysis\n",
    "mercado_stock_trends_df['Lagged Search Trends'] = mercado_stock_trends_df['Search Trends'].shift(1)\n",
    "mercado_stock_trends_df['Stock Volatility'] = mercado_stock_trends_df['close'].pct_change().rolling(window=4).std()\n",
    "mercado_stock_trends_df['Hourly Stock Return'] = mercado_stock_trends_df['close'].pct_change()\n",
    "\n",
    "# Calculate correlations\n",
    "correlation_matrix = mercado_stock_trends_df[['Stock Volatility', 'Lagged Search Trends', 'Hourly Stock Return']].corr()\n",
    "print(\"Correlation Matrix:\")\n",
    "display(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Does a predictable relationship exist between the lagged search traffic and the stock volatility or between the lagged search traffic and the stock price returns?\n",
    "\n",
    "**Answer:** [to be completed after running the analysis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create a Time Series Model with Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prepare the data for Prophet\n",
    "prophet_df = df_mercado_trends.reset_index()\n",
    "prophet_df.columns = ['ds', 'y']\n",
    "\n",
    "# Create and fit the Prophet model\n",
    "model = Prophet()\n",
    "model.fit(prophet_df)\n",
    "\n",
    "# Create future dates for forecasting\n",
    "future_dates = model.make_future_dataframe(periods=2000, freq='H')\n",
    "forecast = model.predict(future_dates)\n",
    "\n",
    "# Plot the forecast\n",
    "fig = model.plot(forecast)\n",
    "plt.title('MercadoLibre Search Traffic Forecast')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot the individual components\n",
    "fig = model.plot_components(forecast)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "1. What time of day exhibits the greatest popularity?\n",
    "**Answer:** [to be completed after running the analysis]\n",
    "\n",
    "2. Which day of week gets the most search traffic?\n",
    "**Answer:** [to be completed after running the analysis]\n",
    "\n",
    "3. What's the lowest point for search traffic in the calendar year?\n",
    "**Answer:** [to be completed after running the analysis]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
